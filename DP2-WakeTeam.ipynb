{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Processing Arquitectura Completa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table with city values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beach</th>\n",
       "      <th>City</th>\n",
       "      <th>Nature</th>\n",
       "      <th>Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barcelona</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilbao</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ibiza</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madrid</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oviedo</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sevilla</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valencia</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Beach  City  Nature  Party\n",
       "Barcelona     10    10       3      8\n",
       "Bilbao         0     9       7      7\n",
       "Ibiza         10     4       9     10\n",
       "Madrid         0    10       3      9\n",
       "Oviedo         0     5       9      4\n",
       "Sevilla        0     7       5      7\n",
       "Valencia       8     9       6      8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "city_list = ['Barcelona', 'Bilbao', 'Ibiza', 'Madrid', 'Oviedo', 'Sevilla', 'Valencia']\n",
    "beach = [10, 0, 10, 0, 0, 0, 8]\n",
    "city = [10, 9, 4, 10, 5, 7, 9]\n",
    "nature = [3, 7, 9, 3, 9, 5, 6]\n",
    "party = [8, 7, 10, 9, 4, 7, 8]\n",
    "d = {'Beach': beach, 'City': city, 'Nature': nature, 'Party': party}\n",
    "\n",
    "cities = pd.DataFrame(data=d, index=city_list)\n",
    "\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create streaming for Flats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyspark import sql\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"QualityLife\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a data processing for the flats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create flats_df stream\n",
    "flats_df_stream = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
    "  .option(\"subscribe\", \"flats\") \\\n",
    "  .load()\n",
    "\n",
    "flats_df_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- house_city: string (nullable = true)\n",
      " |-- house_code: string (nullable = true)\n",
      " |-- house_rent: string (nullable = true)\n",
      " |-- house_rooms: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create schema for flats_df\n",
    "schema_flats = StructType(\n",
    "    [\n",
    "        StructField('house_city', StringType(), True),\n",
    "        StructField('house_code', StringType(), True),\n",
    "        StructField('house_rent', StringType(), True),\n",
    "        StructField('house_rooms', StringType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "flats_df = flats_df_stream.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\", \"timestamp\") \\\n",
    "    .withColumn(\"value\", from_json(\"value\", schema_flats)) \\\n",
    "    .select(col('key'), col(\"timestamp\"), col('value.*'))\n",
    "\n",
    "flats_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f9caeeb2bd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table to store query output in memory\n",
    "flats_df.writeStream \\\n",
    " .outputMode(\"append\") \\\n",
    " .format(\"memory\") \\\n",
    " .option(\"truncate\", \"false\") \\\n",
    " .queryName(\"flats_all\") \\\n",
    " .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+----------+----------+-----------+\n",
      "|key|timestamp|house_city|house_code|house_rent|house_rooms|\n",
      "+---+---------+----------+----------+----------+-----------+\n",
      "+---+---------+----------+----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from flats_all order by timestamp desc\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+----------+----------+-----------+\n",
      "|key|timestamp|house_city|house_code|house_rent|house_rooms|\n",
      "+---+---------+----------+----------+----------+-----------+\n",
      "+---+---------+----------+----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_name = cities.index.values[0]\n",
    "query = \"SELECT * from flats_all WHERE house_city='{}'\".format(city_name)\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create streaming for families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create families_df_stream\n",
    "families_df_stream = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
    "  .option(\"subscribe\", \"families\") \\\n",
    "  .load()\n",
    "\n",
    "families_df_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing_row\n",
    "def processing_row(row):\n",
    "    print(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f9c8b42bb10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "families_df_stream.writeStream \\\n",
    " .foreach(processing_row) \\\n",
    " .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "families_df_query = families_df_stream.writeStream \\\n",
    " .foreach(processing_row) \\\n",
    " .format(\"console\") \\\n",
    " .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- people_name: string (nullable = true)\n",
      " |-- people_age: string (nullable = true)\n",
      " |-- people_members: string (nullable = true)\n",
      " |-- people_salary: string (nullable = true)\n",
      " |-- people_city: string (nullable = true)\n",
      " |-- people_party: string (nullable = true)\n",
      " |-- people_beach: string (nullable = true)\n",
      " |-- people_nature: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create schema for families_df\n",
    "schema_families = StructType(\n",
    "    [\n",
    "        StructField('tweet_id', StringType(), True),\n",
    "        StructField('people_name', StringType(), True),\n",
    "        StructField('people_age', StringType(), True),\n",
    "        StructField('people_members', StringType(), True),\n",
    "        StructField('people_salary', StringType(), True),\n",
    "        StructField('people_city', StringType(), True),\n",
    "        StructField('people_party', StringType(), True),\n",
    "        StructField('people_beach', StringType(), True),\n",
    "        StructField('people_nature', StringType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "families_df = families_df_stream.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\", \"timestamp\") \\\n",
    "    .withColumn(\"value\", from_json(\"value\", schema_families)) \\\n",
    "    .select(col('key'), col(\"timestamp\"), col('value.*'))\n",
    "\n",
    "families_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f9c8af9d350>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processing_row\n",
    "def processing_row(row):\n",
    "    print(row)\n",
    "    \n",
    "spark.udf.register(\"processing_row_udf\", processing_row)\n",
    "    \n",
    "families_df.writeStream.foreach(processing_row).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE FUNCTIONS FOR DATA STREAM\n",
    "\n",
    "# best_city\n",
    "def best_city(df, hobbies):\n",
    "    df = abs(df - hobbies)\n",
    "    df['total'] = df.sum(axis=1)\n",
    "    df = df.sort_values('total')\n",
    "    city = df.index.values[0]\n",
    "    return city\n",
    "\n",
    "# process_row\n",
    "def process_row(row):\n",
    "    # Retrieve best city\n",
    "    hobbies = [row['people_beach'], row['people_city'], row['people_nature'], row['people_party']]\n",
    "    city = best_city(cities, hobbies)\n",
    "    \n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "families_df_query = families_df.writeStream \\\n",
    " .foreach(processing_row) \\\n",
    " .outputMode(\"append\") \\\n",
    " .format(\"memory\") \\\n",
    " .option(\"truncate\", \"false\") \\\n",
    " .queryName(\"families\") \\\n",
    " .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------+-------------------+----------------------+----------+--------------+-------------+-----------+------------+------------+-------------+\n",
      "|key |timestamp              |tweet_id           |people_name           |people_age|people_members|people_salary|people_city|people_party|people_beach|people_nature|\n",
      "+----+-----------------------+-------------------+----------------------+----------+--------------+-------------+-----------+------------+------------+-------------+\n",
      "|null|2021-02-02 19:05:35.943|1356680159227768838|Brooke Payne          |33        |4             |125385       |4          |10          |9           |4            |\n",
      "|null|2021-02-02 19:01:04.643|1356679023200514048|Lee Davis             |28        |2             |130389       |6          |10          |10          |10           |\n",
      "|null|2021-02-02 18:55:33.209|1356677635561172992|Mrs. Amanda Carlson MD|58        |3             |118617       |8          |0           |4           |2            |\n",
      "+----+-----------------------+-------------------+----------------------+----------+--------------+-------------+-----------+------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from families order by timestamp desc\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = families_df.writeStream.format(\"console\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create table to store query output in memory\n",
    "families_df.writeStream \\\n",
    " .outputMode(\"append\") \\\n",
    " .format(\"memory\") \\\n",
    " .option(\"truncate\", \"false\") \\\n",
    " .queryName(\"families_all\") \\\n",
    " .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from families_all order by timestamp desc\").show(truncate = False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
